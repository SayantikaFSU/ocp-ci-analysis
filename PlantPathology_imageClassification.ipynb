{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 25563,
          "databundleVersionId": 2094376,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "PlantPathology_5934_project",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SayantikaFSU/ocp-ci-analysis/blob/master/PlantPathology_imageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'plant-pathology-2021-fgvc8:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F25563%2F2094376%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240518%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240518T154615Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D930090ea8664030c5d80fa83b29236ffc8218d68b169b625235e720a1b4cdb4e2e1cbead926a389c0adc1cb2be0afab7011d6e66496362f4e4e94e6487473118f7b6d568b6b43e150dba9734800882323e5a5e67e68b89575b68311d2f24b9f076490c86fa05c927491699baa4d9bc052880a7af9f65ee4daa36c3fed2f97d5e0733c350c8d072d812df8360a54522926470d1c0eae2b519d4dcf41bcddb2cb4e56984c5b7857e89e504948089116a14c8aa7b8603cb1fe0e7a4b879177807999bc1df7bd7b6e3625ae52b5eb976876a99240ebadd8c7bfce2199cd585a1ae7cccad36a7d86299da70328e5c1a5deba6537e9995f6867ab8ae2fd11b3862a3a2'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WtMyWvk4YePi"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as Fn\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.io import savemat\n",
        "from time import time\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:19.261098Z",
          "iopub.execute_input": "2023-12-16T21:07:19.261566Z",
          "iopub.status.idle": "2023-12-16T21:07:24.092119Z",
          "shell.execute_reply.started": "2023-12-16T21:07:19.261522Z",
          "shell.execute_reply": "2023-12-16T21:07:24.091125Z"
        },
        "trusted": true,
        "id": "TfZQdcwvYePj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTRODUCTION:\n",
        "\n",
        "This notebook deals with Classification of the disease of plants using the 'Plant Pathology 2021 - FGVC8' Dataset.\n",
        "\n",
        "The goal of this notebook is to train a neural network on the train-image dataset and used that trained network to correctly predict the disease of the test images.\n",
        "\n",
        "**********************************************************************************************"
      ],
      "metadata": {
        "id": "DKl2_ulFYePk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:24.093738Z",
          "iopub.execute_input": "2023-12-16T21:07:24.094167Z",
          "iopub.status.idle": "2023-12-16T21:07:24.176152Z",
          "shell.execute_reply.started": "2023-12-16T21:07:24.09414Z",
          "shell.execute_reply": "2023-12-16T21:07:24.175155Z"
        },
        "trusted": true,
        "id": "jvS_XNW9YePk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.10-cp37-cp37m-linux_x86_64.whl\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:24.177299Z",
          "iopub.execute_input": "2023-12-16T21:07:24.177753Z",
          "iopub.status.idle": "2023-12-16T21:07:24.184915Z",
          "shell.execute_reply.started": "2023-12-16T21:07:24.177656Z",
          "shell.execute_reply": "2023-12-16T21:07:24.182065Z"
        },
        "trusted": true,
        "id": "YeIDrhfqYePl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "\n",
        "# Set device to TPU\n",
        "#device = xm.xla_device()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:24.189436Z",
          "iopub.execute_input": "2023-12-16T21:07:24.189986Z",
          "iopub.status.idle": "2023-12-16T21:07:24.194433Z",
          "shell.execute_reply.started": "2023-12-16T21:07:24.189955Z",
          "shell.execute_reply": "2023-12-16T21:07:24.193426Z"
        },
        "trusted": true,
        "id": "yOxNR1voYePl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASETS PROVIDED:\n",
        "\n",
        "\n",
        "Here the image data is provided in two directories\n",
        "\n",
        "(1) train_images : contains 18632 .jpg images\n",
        "\n",
        "(2) test_images : contains 3  .jpg images\n",
        "\n",
        "(3) train.csv : a csv file containing two columns providing the train image filename and the disease labels\n",
        "\n",
        "************************************************************************************"
      ],
      "metadata": {
        "id": "bmV3cxJCYePl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/kaggle/input/plant-pathology-2021-fgvc8/train.csv'\n",
        "\n",
        "train_dir ='/kaggle/input/plant-pathology-2021-fgvc8/train_images'\n",
        "test_dir='/kaggle/input/plant-pathology-2021-fgvc8/test_images'\n",
        "\n",
        "train=pd.read_csv(train_path)\n",
        "\n",
        "\n",
        "print(f'Number of images = {len(train)}')\n",
        "\n",
        "train.head(4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:24.196169Z",
          "iopub.execute_input": "2023-12-16T21:07:24.197048Z",
          "iopub.status.idle": "2023-12-16T21:07:24.256843Z",
          "shell.execute_reply.started": "2023-12-16T21:07:24.196899Z",
          "shell.execute_reply": "2023-12-16T21:07:24.25586Z"
        },
        "trusted": true,
        "id": "8tjH7S8QYePl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting one image\n",
        "\n",
        "i=0\n",
        "\n",
        "name_img = train.iloc[i, 0]\n",
        "label_name_img=train.iloc[i,1]\n",
        "\n",
        "img = Image.open(os.path.join(train_dir, name_img[:-4]+\".jpg\"))\n",
        "plt.imshow(img)\n",
        "plt.title(label_name_img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:24.258204Z",
          "iopub.execute_input": "2023-12-16T21:07:24.258597Z",
          "iopub.status.idle": "2023-12-16T21:07:26.82916Z",
          "shell.execute_reply.started": "2023-12-16T21:07:24.258561Z",
          "shell.execute_reply": "2023-12-16T21:07:26.828175Z"
        },
        "trusted": true,
        "id": "rt_7OJxcYePl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images are seen to be really big in size so I transformed them into smaller 128 x 128 size to handle easily"
      ],
      "metadata": {
        "id": "q4HMiMOrYePl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img=np.array(img)\n",
        "img.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:26.830354Z",
          "iopub.execute_input": "2023-12-16T21:07:26.830643Z",
          "iopub.status.idle": "2023-12-16T21:07:26.900392Z",
          "shell.execute_reply.started": "2023-12-16T21:07:26.830617Z",
          "shell.execute_reply": "2023-12-16T21:07:26.899467Z"
        },
        "trusted": true,
        "id": "FgrKto--YePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CATEGORIES OF DISEASE:\n",
        "\n",
        "We can observe there are 12 categories of disease.\n",
        "\n",
        "Although the count plot shows that there exists an imbalance between the categories, so usual cross-entropy loss would not be a good fit for the loss function, since it is biased towards the dominant classes.\n",
        "\n",
        "********************************************************************************************"
      ],
      "metadata": {
        "id": "rkuMGY30YePm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot of label categories\n",
        "\n",
        "# Count the occurrences of each category\n",
        "category_counts = train['labels'].value_counts()\n",
        "print(category_counts)\n",
        "print(f\"number of categories={len(category_counts)}\")\n",
        "\n",
        "category_counts.index"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:26.901474Z",
          "iopub.execute_input": "2023-12-16T21:07:26.901751Z",
          "iopub.status.idle": "2023-12-16T21:07:26.91781Z",
          "shell.execute_reply.started": "2023-12-16T21:07:26.901726Z",
          "shell.execute_reply": "2023-12-16T21:07:26.916898Z"
        },
        "trusted": true,
        "id": "UYwNFqxdYePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['labels'].value_counts().plot(kind='bar')\n",
        "plt.suptitle('Count Plot of different disease category')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:26.919089Z",
          "iopub.execute_input": "2023-12-16T21:07:26.919672Z",
          "iopub.status.idle": "2023-12-16T21:07:27.271385Z",
          "shell.execute_reply.started": "2023-12-16T21:07:26.919638Z",
          "shell.execute_reply": "2023-12-16T21:07:27.270491Z"
        },
        "trusted": true,
        "id": "zgvNzj43YePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMAGES of leaves belonging to DIFFERENT CATEGORIES\n",
        "\n",
        "************************************************************"
      ],
      "metadata": {
        "id": "k8X5cyDXYePm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display images belonging to a class:\n",
        "\n",
        "def show_image(class_name, examples):\n",
        "    image_list=train[train['labels']==class_name]['image'][0:examples].to_list()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    for i in range(0,len(image_list)):\n",
        "        name_img = image_list[i]\n",
        "        img = Image.open(os.path.join(train_dir, name_img[:-4]+\".jpg\"))\n",
        "        img.resize ((128,128),resample=Image.BICUBIC)\n",
        "\n",
        "\n",
        "        plt.subplot(1 ,examples, i%examples +1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_name)\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "#show_image('healthy',3)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:27.274648Z",
          "iopub.execute_input": "2023-12-16T21:07:27.274963Z",
          "iopub.status.idle": "2023-12-16T21:07:27.281756Z",
          "shell.execute_reply.started": "2023-12-16T21:07:27.274934Z",
          "shell.execute_reply": "2023-12-16T21:07:27.280875Z"
        },
        "trusted": true,
        "id": "12D38jSgYePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_list=['scab', 'healthy', 'frog_eye_leaf_spot', 'rust', 'complex',\n",
        "       'powdery_mildew', 'scab frog_eye_leaf_spot',\n",
        "       'scab frog_eye_leaf_spot complex', 'frog_eye_leaf_spot complex',\n",
        "       'rust frog_eye_leaf_spot', 'rust complex', 'powdery_mildew complex']\n",
        "\n",
        "for k in range(0,len(class_list)):\n",
        "    class_name=class_list[k]\n",
        "    show_image(class_name,2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:07:27.282817Z",
          "iopub.execute_input": "2023-12-16T21:07:27.283123Z",
          "iopub.status.idle": "2023-12-16T21:08:28.580361Z",
          "shell.execute_reply.started": "2023-12-16T21:07:27.283098Z",
          "shell.execute_reply": "2023-12-16T21:08:28.579351Z"
        },
        "trusted": true,
        "id": "ftdsuDcnYePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELS CONSIDERED:\n",
        "****************************************************************"
      ],
      "metadata": {
        "id": "kfpA3J-AYePm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformation:\n",
        "\n",
        "Since the images are really big in size I used the following function to reduce them to 128 x 128 and also transform them into tensors\n"
      ],
      "metadata": {
        "id": "Fjfa2wsPYePm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform all the training data into tensors\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torchvision import transforms,datasets\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, RandomCrop,ToTensor, Normalize, Grayscale, RandomRotation,InterpolationMode\n",
        "from torchvision.transforms.v2 import  RandomResize\n",
        "\n",
        "# Define data transformations\n",
        "transform = Compose([\n",
        "    Resize([128, 128],interpolation=InterpolationMode.BICUBIC),\n",
        "    ToTensor()\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:28.581698Z",
          "iopub.execute_input": "2023-12-16T21:08:28.582357Z",
          "iopub.status.idle": "2023-12-16T21:08:28.630453Z",
          "shell.execute_reply.started": "2023-12-16T21:08:28.582323Z",
          "shell.execute_reply": "2023-12-16T21:08:28.629634Z"
        },
        "trusted": true,
        "id": "EzzS2ZUtYePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 1:\n",
        "\n",
        "The first model I considered is a CNN model with four layers described as below\n",
        "\n",
        "*********************************************************************************************"
      ],
      "metadata": {
        "id": "0hq9XTExYePn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN model:\n",
        "\n",
        "layer 1 :conv-relu-maxpool-dropout\n",
        "\n",
        "layer 2 :conv-relu-maxpool-dropout\n",
        "\n",
        "layer 3 :conv-relu-maxpool-dropout\n",
        "\n",
        "layer 4 :conv-relu-maxpool-dropout\n",
        "\n",
        "*********************************************************************************\n"
      ],
      "metadata": {
        "id": "eDy4plgwYePn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CUSTOM DATASET to preprocess the data for the model\n",
        "*********************************************************\n",
        "\n",
        "train.csv : contains the image names and labels\n",
        "\n",
        "train_dir : contains the images\n",
        "\n",
        "Custom Dataset returns the image_tensor and the corresponding text_labels"
      ],
      "metadata": {
        "id": "jaqcfPwDYePn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomTextLabelDataset(Dataset):\n",
        "    def __init__(self, csv_path, image_dir, transform=None):\n",
        "        self.csv_path = csv_path\n",
        "        self.images_root = image_dir\n",
        "        self.transform = transform\n",
        "        self.data = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        # Load data from the CSV file\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        # Combine filename and label information\n",
        "        data = [{'filename': row['image'], 'label': row['labels']} for _, row in df.iterrows()]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        entry = self.data[index]\n",
        "        image_path = os.path.join(self.images_root, entry['filename'])\n",
        "        text_label = entry['label']\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, text_label\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:28.631755Z",
          "iopub.execute_input": "2023-12-16T21:08:28.632047Z",
          "iopub.status.idle": "2023-12-16T21:08:28.642099Z",
          "shell.execute_reply.started": "2023-12-16T21:08:28.632023Z",
          "shell.execute_reply": "2023-12-16T21:08:28.641236Z"
        },
        "trusted": true,
        "id": "jjPlVF0eYePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to CSV file and images directory:\n",
        "csv_path = '/kaggle/input/plant-pathology-2021-fgvc8/train.csv'\n",
        "images_root = '/kaggle/input/plant-pathology-2021-fgvc8/train_images'\n",
        "\n",
        "## dataset:\n",
        "full_dataset = CustomTextLabelDataset(csv_path=csv_path, image_dir=images_root, transform=transform)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:28.643328Z",
          "iopub.execute_input": "2023-12-16T21:08:28.64408Z",
          "iopub.status.idle": "2023-12-16T21:08:29.812661Z",
          "shell.execute_reply.started": "2023-12-16T21:08:28.644045Z",
          "shell.execute_reply": "2023-12-16T21:08:29.811828Z"
        },
        "trusted": true,
        "id": "QRF2-h5xYePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#access label\n",
        "full_dataset[0][1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:29.813804Z",
          "iopub.execute_input": "2023-12-16T21:08:29.8141Z",
          "iopub.status.idle": "2023-12-16T21:08:29.990944Z",
          "shell.execute_reply.started": "2023-12-16T21:08:29.814074Z",
          "shell.execute_reply": "2023-12-16T21:08:29.990151Z"
        },
        "trusted": true,
        "id": "x839GmpbYePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOSS FUNCTION: FOCAL LOSS\n",
        "*******************************************************\n",
        "\n",
        "Since we have a pretty significant imbalance in the category counts the classic cross entropy loss would show that less frequent classes will having a more significant loss.\n",
        "\n",
        "\n",
        "Focal Loss is a modification of the standard cross-entropy loss, designed to address the problem of class imbalance in binary and multi-class classification tasks.\n",
        "The focal loss is a finetuned cross-entropy loss that puts emphasis on classes with a high loss and give less importance to classes with low loss. This regularisation term pushes the model to focus on learning rare classes and put less emphasis on dominant classes.\n",
        "It was introduced in the paper titled \"Focal Loss for Dense Object Detection\" by Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll√°r.\n",
        "\n",
        "The Focal Loss (FL) is defined as follows:\n",
        "\n",
        "https://doi.org/10.48550/arXiv.1708.02002"
      ],
      "metadata": {
        "id": "LmlUv13FYePn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "********************************\n",
        "The CNN model with four layers explained earlier\n"
      ],
      "metadata": {
        "id": "ctclY3MaYePn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN_model(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN_model, self).__init__()\n",
        "\n",
        "        #### 1st Convolutional Layer\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #### 2nd Convolutional Layer\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #### 3rd Convolutional Layer\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #### 4th Convolutional Layer\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu4 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        ### Fully Connected Layer\n",
        "        self.fc = nn.Linear(128 * 8 * 8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
        "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
        "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
        "        x = self.maxpool4(self.relu4(self.conv4(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "num_classes = 12  # we have 12 classes here\n",
        "model = CNN_model(num_classes)\n",
        "\n",
        "model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:29.992086Z",
          "iopub.execute_input": "2023-12-16T21:08:29.992384Z",
          "iopub.status.idle": "2023-12-16T21:08:30.01562Z",
          "shell.execute_reply.started": "2023-12-16T21:08:29.992359Z",
          "shell.execute_reply": "2023-12-16T21:08:30.014846Z"
        },
        "trusted": true,
        "id": "IUudW4dxYePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An IMPLEMENTATION OF FOCAL LOSS function using Pytorch:\n",
        "******************************************\n",
        "\n",
        "here,\n",
        "\n",
        "alpha = balancing factor to handle the class imbalance computed sample wise\n",
        "\n",
        "gamma =  a focusing parameter that allows the model to down-weight easy examples\n",
        "\n",
        "alpha and gamma are hyperparameters that can be adjusted based on specific problem and dataset. The reduction parameter specifies how the losses from individual samples should be aggregated.\n",
        "\n",
        "Returns average focul loss from all the samples"
      ],
      "metadata": {
        "id": "GV1f9vIUYePn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "\n",
        "        #focul loss\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha*(1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        #if self.alpha is not None:\n",
        "            #alpha_factor = self.alpha[targets]\n",
        "            #focal_loss = focal_loss * alpha_factor\n",
        "\n",
        "\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        elif self.reduction == 'none':\n",
        "            return focal_loss\n",
        "        else:\n",
        "            raise ValueError(\"Invalid reduction option. Use 'mean', 'sum', or 'none'.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:30.016641Z",
          "iopub.execute_input": "2023-12-16T21:08:30.016901Z",
          "iopub.status.idle": "2023-12-16T21:08:30.027075Z",
          "shell.execute_reply.started": "2023-12-16T21:08:30.016878Z",
          "shell.execute_reply": "2023-12-16T21:08:30.02619Z"
        },
        "trusted": true,
        "id": "4qz3o1AvYePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the labels are given in text format I made a mapping to turn text into numerics and vice-versa\n",
        "*********************"
      ],
      "metadata": {
        "id": "myCRDvRvYePo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping between text labels and numerical indices\n",
        "unique_text_labels = class_list\n",
        "label_to_index = {label: index for index, label in enumerate(unique_text_labels)}\n",
        "index_to_label = {index: label for label, index in label_to_index.items()}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:30.028159Z",
          "iopub.execute_input": "2023-12-16T21:08:30.028486Z",
          "iopub.status.idle": "2023-12-16T21:08:30.036917Z",
          "shell.execute_reply.started": "2023-12-16T21:08:30.028456Z",
          "shell.execute_reply": "2023-12-16T21:08:30.036056Z"
        },
        "trusted": true,
        "id": "S2ZqSarCYePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING ON train_images:\n",
        "*************************************************************************************************\n",
        "Used Adam optimizer with learning rate 0.01.\n",
        "\n",
        "\n",
        "the model is saved locally at 'cnn_model.pth'"
      ],
      "metadata": {
        "id": "hE77LilgYePo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "#from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define the focal loss function and optimizer:\n",
        "criterion = FocalLoss(gamma=2, alpha=1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#step_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Wrap model and optimizer with XLA\n",
        "#model, optimizer = xm.initialize_model(model, optimizer, opt_level=\"O2\")\n",
        "\n",
        "\n",
        "# Split the dataset into training and validation sets: 80:20\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "print(len(train_dataset))\n",
        "\n",
        "# Create data loaders for training and validation\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(len(train_loader))\n",
        "\n",
        "\n",
        "# Use GPU for model\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    ## Training loop:\n",
        "\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    #run=0\n",
        "    for inputs, text_labels in train_loader:\n",
        "        inputs, text_labels = inputs.to(device), text_labels\n",
        "\n",
        "        #print('input',inputs)\n",
        "        #print('text_labels',text_labels)\n",
        "        #print(inputs.shape)\n",
        "\n",
        "        # Convert text labels to numerical indices using the mapping\n",
        "        numerical_labels = [label_to_index[label] for label in text_labels]\n",
        "        #print((numerical_labels))\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        #print(outputs.shape)\n",
        "        #print(torch.tensor(numerical_labels).shape)\n",
        "\n",
        "        loss=criterion(outputs, torch.tensor(numerical_labels).to(device))  # Focal Loss\n",
        "\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update the weights\n",
        "\n",
        "        #print(f'{run}run done')\n",
        "        #run=run+1\n",
        "\n",
        "    #print(f'train loss for {epoch+1} epoch = {loss:0.3f} ')\n",
        "\n",
        "    ###Validation loop:\n",
        "\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, text_labels in val_loader:\n",
        "            inputs, text_labels = inputs.to(device), text_labels\n",
        "\n",
        "\n",
        "            numerical_labels = [label_to_index[label] for label in text_labels]\n",
        "            numerical_labels=torch.tensor(numerical_labels).to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += len(numerical_labels)\n",
        "            correct += (predicted == numerical_labels).sum().item()\n",
        "\n",
        "            #step_scheduler.step()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Set Loss: {loss.item():.4f}, Validation Set Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-16T21:08:30.038176Z",
          "iopub.execute_input": "2023-12-16T21:08:30.03857Z",
          "iopub.status.idle": "2023-12-17T03:30:21.449259Z",
          "shell.execute_reply.started": "2023-12-16T21:08:30.038545Z",
          "shell.execute_reply": "2023-12-17T03:30:21.448228Z"
        },
        "trusted": true,
        "id": "Wl44xBPeYePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Save the trained model:\n",
        "torch.save(model.state_dict(), 'cnn_model.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T03:40:49.152881Z",
          "iopub.execute_input": "2023-12-17T03:40:49.154127Z",
          "iopub.status.idle": "2023-12-17T03:40:49.161974Z",
          "shell.execute_reply.started": "2023-12-17T03:40:49.15407Z",
          "shell.execute_reply": "2023-12-17T03:40:49.161201Z"
        },
        "trusted": true,
        "id": "5hPLDqxdYePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICTION ON TEST IMAGES:\n",
        "\n",
        "*****************************************************************************"
      ],
      "metadata": {
        "id": "WMePUcLNYePo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### On test data:\n",
        "\n",
        "#Step 1:\n",
        "\n",
        "# Load the saved model state dict\n",
        "model.load_state_dict(torch.load('/kaggle/working/cnn_model.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T03:41:01.506143Z",
          "iopub.execute_input": "2023-12-17T03:41:01.507026Z",
          "iopub.status.idle": "2023-12-17T03:41:01.517993Z",
          "shell.execute_reply.started": "2023-12-17T03:41:01.506978Z",
          "shell.execute_reply": "2023-12-17T03:41:01.517064Z"
        },
        "trusted": true,
        "id": "PjLsRJaSYePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 2: Prepare Test Data\n",
        "test_dir = '/kaggle/input/plant-pathology-2021-fgvc8/test_images'\n",
        "\n",
        "os.listdir(test_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T03:30:21.480257Z",
          "iopub.execute_input": "2023-12-17T03:30:21.480578Z",
          "iopub.status.idle": "2023-12-17T03:30:21.493841Z",
          "shell.execute_reply.started": "2023-12-17T03:30:21.480544Z",
          "shell.execute_reply": "2023-12-17T03:30:21.492981Z"
        },
        "trusted": true,
        "id": "1kxuT1fDYePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(test_dir):\n",
        "    img_path=os.path.join(test_dir,filename)\n",
        "    img=Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    img_tensor=transform(img).unsqueeze(0)\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred=model(img_tensor.to(device))\n",
        "        #print(pred.shape)\n",
        "\n",
        "        predicted_class = torch.argmax(pred).item()\n",
        "        predicted_text_class=index_to_label[predicted_class]\n",
        "        print(f\"Image: {filename}, Predicted Class: {predicted_text_class}\")\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T03:30:21.49484Z",
          "iopub.execute_input": "2023-12-17T03:30:21.495116Z",
          "iopub.status.idle": "2023-12-17T03:30:28.172047Z",
          "shell.execute_reply.started": "2023-12-17T03:30:21.495092Z",
          "shell.execute_reply": "2023-12-17T03:30:28.171065Z"
        },
        "trusted": true,
        "id": "eKwQtEdhYePp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2:\n",
        "\n",
        "CNN:\n",
        "\n",
        "4 layers like Model 1 with a dropout at the end\n",
        "\n",
        "****************************************************************************************"
      ],
      "metadata": {
        "id": "GDSJLKrOYePp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN_model_dropout(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN_model_dropout, self).__init__()\n",
        "\n",
        "        #### 1st Convolutional Layer\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        #### 2nd Convolutional Layer\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        #### 3rd Convolutional Layer\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        #### 4th Convolutional Layer\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        # ReLU activation\n",
        "        self.relu4 = nn.ReLU()\n",
        "        # Max-pooling layer\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout4 = nn.Dropout(0.25)\n",
        "\n",
        "        ### Fully Connected Layer\n",
        "        self.fc = nn.Linear(128 * 8 * 8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
        "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
        "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
        "        x = self.maxpool4(self.relu4(self.conv4(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "num_classes = 12  # we have 12 classes here\n",
        "model = CNN_model(num_classes)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T03:55:34.124538Z",
          "iopub.execute_input": "2023-12-17T03:55:34.124946Z",
          "iopub.status.idle": "2023-12-17T03:55:34.145333Z",
          "shell.execute_reply.started": "2023-12-17T03:55:34.124913Z",
          "shell.execute_reply": "2023-12-17T03:55:34.144492Z"
        },
        "trusted": true,
        "id": "6s0D6txUYePp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "#from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define the focal loss function and optimizer:\n",
        "criterion = FocalLoss(gamma=2, alpha=1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#step_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Wrap model and optimizer with XLA\n",
        "#model, optimizer = xm.initialize_model(model, optimizer, opt_level=\"O2\")\n",
        "\n",
        "\n",
        "# Split the dataset into training and validation sets: 80:20\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "print(len(train_dataset))\n",
        "\n",
        "# Create data loaders for training and validation\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(len(train_loader))\n",
        "\n",
        "\n",
        "# Use GPU for model\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "epochs = 8\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    ## Training loop:\n",
        "\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    #run=0\n",
        "    for inputs, text_labels in train_loader:\n",
        "        inputs, text_labels = inputs.to(device), text_labels\n",
        "\n",
        "        #print('input',inputs)\n",
        "        #print('text_labels',text_labels)\n",
        "        #print(inputs.shape)\n",
        "\n",
        "        # Convert text labels to numerical indices using the mapping\n",
        "        numerical_labels = [label_to_index[label] for label in text_labels]\n",
        "        #print((numerical_labels))\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        #print(outputs.shape)\n",
        "        #print(torch.tensor(numerical_labels).shape)\n",
        "\n",
        "        loss=criterion(outputs, torch.tensor(numerical_labels).to(device))  # Focal Loss\n",
        "\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update the weights\n",
        "\n",
        "        #print(f'{run}run done')\n",
        "        #run=run+1\n",
        "\n",
        "    #print(f'train loss for {epoch+1} epoch = {loss:0.3f} ')\n",
        "\n",
        "    ###Validation loop:\n",
        "\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, text_labels in val_loader:\n",
        "            inputs, text_labels = inputs.to(device), text_labels\n",
        "\n",
        "\n",
        "            numerical_labels = [label_to_index[label] for label in text_labels]\n",
        "            numerical_labels=torch.tensor(numerical_labels).to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += len(numerical_labels)\n",
        "            correct += (predicted == numerical_labels).sum().item()\n",
        "\n",
        "            #step_scheduler.step()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Set Loss: {loss.item():.4f}, Validation Set Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "## Save the trained model:\n",
        "torch.save(model.state_dict(), 'cnn_model_dropout.pth')\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T03:58:29.078255Z",
          "iopub.execute_input": "2023-12-17T03:58:29.078674Z",
          "iopub.status.idle": "2023-12-17T09:05:06.327057Z",
          "shell.execute_reply.started": "2023-12-17T03:58:29.07864Z",
          "shell.execute_reply": "2023-12-17T09:05:06.326068Z"
        },
        "trusted": true,
        "id": "Wfv7vMJ3YePp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### On test data:\n",
        "\n",
        "#Step 1:\n",
        "\n",
        "# Load the saved model state dict\n",
        "model.load_state_dict(torch.load('/kaggle/working/cnn_model_dropout.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T09:05:06.32885Z",
          "iopub.execute_input": "2023-12-17T09:05:06.329162Z",
          "iopub.status.idle": "2023-12-17T09:05:06.339247Z",
          "shell.execute_reply.started": "2023-12-17T09:05:06.329135Z",
          "shell.execute_reply": "2023-12-17T09:05:06.33828Z"
        },
        "trusted": true,
        "id": "AlXhPV9nYePp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(test_dir):\n",
        "    img_path=os.path.join(test_dir,filename)\n",
        "    img=Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    img_tensor=transform(img).unsqueeze(0)\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred=model(img_tensor.to(device))\n",
        "        #print(pred.shape)\n",
        "\n",
        "        predicted_class = torch.argmax(pred).item()\n",
        "        predicted_text_class=index_to_label[predicted_class]\n",
        "        print(f\"Image: {filename}, Predicted Class: {predicted_text_class}\")\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-17T09:05:06.34042Z",
          "iopub.execute_input": "2023-12-17T09:05:06.340752Z",
          "iopub.status.idle": "2023-12-17T09:05:12.312625Z",
          "shell.execute_reply.started": "2023-12-17T09:05:06.34071Z",
          "shell.execute_reply": "2023-12-17T09:05:12.311636Z"
        },
        "trusted": true,
        "id": "0-L8vMiTYePp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MCVKPU3YePp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}