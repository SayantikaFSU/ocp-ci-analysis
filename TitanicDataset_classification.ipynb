{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3136,
          "databundleVersionId": 26502,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30615,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "TitanicDataset_5934",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SayantikaFSU/ocp-ci-analysis/blob/master/TitanicDataset_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'titanic:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3136%2F26502%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240518%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240518T154025Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D78fa71ac86018f8e9f546b1008412df4de77d9d58d4784468ceee50c871c2a30e7f3c58460c8017d062929c55c040e0cd429b3700eadb7103d505f22b3ea1f391e66297ec9323277c1989bbf7bed51110781c7eacbc898cb47cc7918c1988faf4e132df56d6996d6248494fbb4632e72f1efb5047969bd2434f942c3a358b70d242c158a9fce4c66797f709c7b7c85a9d14035a8c3ea11557284ae70bea45f37bf1a3ba57b07cb1c18cc6996fcd6b59a938c46a91de2a14bef168cc81fef8a7f0238e9be89a8c5707109521237693fb07414f1deb402758ad820f3d495a20ffea82c818fc122c2effd6710b7bbdee9311d412eec08708d7f6bb1c54450d088ff'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "RDMcLz30XIqn"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:01.018907Z",
          "iopub.execute_input": "2023-12-13T17:41:01.019293Z",
          "iopub.status.idle": "2023-12-13T17:41:01.346505Z",
          "shell.execute_reply.started": "2023-12-13T17:41:01.019265Z",
          "shell.execute_reply": "2023-12-13T17:41:01.345353Z"
        },
        "trusted": true,
        "id": "QxWe5KtaXIqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import re"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:01.348464Z",
          "iopub.execute_input": "2023-12-13T17:41:01.349023Z",
          "iopub.status.idle": "2023-12-13T17:41:02.120155Z",
          "shell.execute_reply.started": "2023-12-13T17:41:01.348985Z",
          "shell.execute_reply": "2023-12-13T17:41:02.118778Z"
        },
        "trusted": true,
        "id": "lu2kUcyjXIqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_path='/kaggle/input/titanic/test.csv'\n",
        "train_path='/kaggle/input/titanic/train.csv'\n",
        "\n",
        "\n",
        "#print(train.head(2),test.head(2))\n",
        "#print(train.shape)\n",
        "#print(train.columns)\n",
        "#print(train.head(5))\n",
        "#print(train.info())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.121978Z",
          "iopub.execute_input": "2023-12-13T17:41:02.12245Z",
          "iopub.status.idle": "2023-12-13T17:41:02.128569Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.122406Z",
          "shell.execute_reply": "2023-12-13T17:41:02.127466Z"
        },
        "trusted": true,
        "id": "VzNe0XIOXIqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis:\n",
        "*******************************************************"
      ],
      "metadata": {
        "id": "IqxaP48hXIqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.130821Z",
          "iopub.execute_input": "2023-12-13T17:41:02.131239Z",
          "iopub.status.idle": "2023-12-13T17:41:02.293309Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.131214Z",
          "shell.execute_reply": "2023-12-13T17:41:02.292371Z"
        },
        "trusted": true,
        "id": "PEdzyJPIXIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(train_path)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.294858Z",
          "iopub.execute_input": "2023-12-13T17:41:02.295211Z",
          "iopub.status.idle": "2023-12-13T17:41:02.34289Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.295181Z",
          "shell.execute_reply": "2023-12-13T17:41:02.341762Z"
        },
        "trusted": true,
        "id": "DBsGTSgJXIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### (1) Pie chart showing the percentage of survived vs dead:\n",
        "\n",
        "\n",
        "# Count the occurrences of each category\n",
        "category_counts = df['Survived'].value_counts()\n",
        "\n",
        "# Plot a pie chart\n",
        "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightcoral'])\n",
        "plt.title('PiePlot of Survived(1) vs Not Survived(0)')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.344723Z",
          "iopub.execute_input": "2023-12-13T17:41:02.345645Z",
          "iopub.status.idle": "2023-12-13T17:41:02.480992Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.345555Z",
          "shell.execute_reply": "2023-12-13T17:41:02.479934Z"
        },
        "trusted": true,
        "id": "V06Ugdw2XIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###(2) 'Sex' wise survival rate and bar plot:\n",
        "\n",
        "# Total females\n",
        "totalFemales = len(df[df.Sex == 'female'])\n",
        "# Total males\n",
        "totalMales = len(df[df.Sex == 'male'])\n",
        "\n",
        "# We added total 1s in the 'Survived' col each of female and male category\n",
        "femalesSurvived = df.loc[df.Sex == 'female']['Survived'].values.sum()\n",
        "malesSurvived = df.loc[df.Sex == 'male']['Survived'].values.sum()\n",
        "\n",
        "print('Total females survived: ', femalesSurvived, '/', totalFemales, 'i.e', round(femalesSurvived*100/totalFemales,2), '% survival rate')\n",
        "print('Total males survived: ', malesSurvived, '/', totalMales, 'i.e', round(malesSurvived*100/totalMales,2), '% survival rate')\n",
        "\n",
        "\n",
        "\n",
        "sns.countplot(df, x= \"Sex\", hue='Survived')\n",
        "plt.title(\"'Sex'-wise survival rate\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.482148Z",
          "iopub.execute_input": "2023-12-13T17:41:02.482406Z",
          "iopub.status.idle": "2023-12-13T17:41:02.704428Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.482383Z",
          "shell.execute_reply": "2023-12-13T17:41:02.703321Z"
        },
        "trusted": true,
        "id": "qGpXZO6ZXIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### (3) Embarked wise Survived plot\n",
        "\n",
        "sns.countplot(df, x= \"Embarked\", hue='Survived')\n",
        "plt.title(\"'Embarked'-wise survival rate\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.705872Z",
          "iopub.execute_input": "2023-12-13T17:41:02.706139Z",
          "iopub.status.idle": "2023-12-13T17:41:02.955242Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.706115Z",
          "shell.execute_reply": "2023-12-13T17:41:02.954144Z"
        },
        "trusted": true,
        "id": "lvgjlPrKXIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### (4) Class wise survival Rate\n",
        "\n",
        "sns.countplot(df, x= \"Pclass\", hue='Survived')\n",
        "plt.title(\"PClass-wise survival rate\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:02.956635Z",
          "iopub.execute_input": "2023-12-13T17:41:02.956901Z",
          "iopub.status.idle": "2023-12-13T17:41:03.215502Z",
          "shell.execute_reply.started": "2023-12-13T17:41:02.956877Z",
          "shell.execute_reply": "2023-12-13T17:41:03.214331Z"
        },
        "trusted": true,
        "id": "3Ls1MtfGXIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### (5) Fare on Survival Rate:\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "ax=sns.histplot(df.loc[(df['Survived'] == 0),'Fare'] ,bins=10, color= '#557C55',label='not survived',kde=True)\n",
        "ax=sns.histplot(df.loc[(df['Survived'] == 1),'Fare'] ,bins=10, color= '#7B68EE', label='survived', kde=True)\n",
        "\n",
        "plt.title('Fare Distribution vs Survival Rate ')\n",
        "plt.xlabel(\"Fare\")\n",
        "plt.ylabel('Frequency');\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:03.219709Z",
          "iopub.execute_input": "2023-12-13T17:41:03.220047Z",
          "iopub.status.idle": "2023-12-13T17:41:03.688296Z",
          "shell.execute_reply.started": "2023-12-13T17:41:03.220014Z",
          "shell.execute_reply": "2023-12-13T17:41:03.687647Z"
        },
        "trusted": true,
        "id": "Rkpeb0QxXIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## (6) Age on Survival Rate:\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "ax=sns.histplot(df.loc[(df['Survived'] == 0),'Age'] ,bins=10, color= '#557C55',label='not survived',kde=True)\n",
        "ax=sns.histplot(df.loc[(df['Survived'] == 1),'Age'] ,bins=10, color= '#7B68EE', label='survived', kde=True)\n",
        "\n",
        "plt.title('Age Distribution vs Survival Rate ')\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel('Frequency');\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:03.68931Z",
          "iopub.execute_input": "2023-12-13T17:41:03.689844Z",
          "iopub.status.idle": "2023-12-13T17:41:04.117071Z",
          "shell.execute_reply.started": "2023-12-13T17:41:03.689818Z",
          "shell.execute_reply": "2023-12-13T17:41:04.115664Z"
        },
        "trusted": true,
        "id": "49wuAg49XIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###(6)Pair Plot:\n",
        "\n",
        "pair_plt=sns.pairplot(df,hue='Survived',palette = 'seismic')\n",
        "\n",
        "pair_plt.fig.suptitle('Pair Plot of Survived vs Other Numerical Predictors', y=1.02, fontsize=14)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:41:43.619494Z",
          "iopub.execute_input": "2023-12-13T17:41:43.619887Z",
          "iopub.status.idle": "2023-12-13T17:41:57.101437Z",
          "shell.execute_reply.started": "2023-12-13T17:41:43.61985Z",
          "shell.execute_reply": "2023-12-13T17:41:57.100503Z"
        },
        "trusted": true,
        "id": "axjDyT8zXIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:\n",
        "****************************************************************"
      ],
      "metadata": {
        "id": "ZOYahsTeXIqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import re\n",
        "from xgboost import XGBClassifier\n",
        "import warnings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:04.124837Z",
          "iopub.execute_input": "2023-12-13T17:42:04.125231Z",
          "iopub.status.idle": "2023-12-13T17:42:04.290988Z",
          "shell.execute_reply.started": "2023-12-13T17:42:04.125198Z",
          "shell.execute_reply": "2023-12-13T17:42:04.28973Z"
        },
        "trusted": true,
        "id": "ZNDlaVi7XIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIsHa4IeXIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==================== Functions ============================ #\n",
        "# This section contains various functions used in the project #\n",
        "# These all perform specific tasks                            #\n",
        "# =========================================================== #\n",
        "\n",
        "\n",
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:05.444467Z",
          "iopub.execute_input": "2023-12-13T17:42:05.445163Z",
          "iopub.status.idle": "2023-12-13T17:42:05.451384Z",
          "shell.execute_reply.started": "2023-12-13T17:42:05.445126Z",
          "shell.execute_reply": "2023-12-13T17:42:05.450147Z"
        },
        "trusted": true,
        "id": "5UwgDB0aXIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing_train(train_path):\n",
        "\n",
        "    data=pd.read_csv(train_path)\n",
        "\n",
        "    #(1):convert Sex to numeric:\n",
        "    data['Sex'] = data['Sex'].map({'male': 1, 'female': 0})\n",
        "\n",
        "    #(2)set embarked to S if not stated:\n",
        "    data['Embarked'] = data['Embarked'].fillna('S')\n",
        "    data['Embarked'] = data['Embarked'].map({'Q': 2, 'S': 1, 'C': 0})\n",
        "\n",
        "     #(3)feature engineering: add feature that tells whether a passenger had a cabin on the Titanic\n",
        "    #use this since basin numbers are not usable\n",
        "    data['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "\n",
        "    #(4) Create new feature FamilySize as a combination of SibSp and Parch\n",
        "    data['Family_Size'] = data['SibSp'] + data['Parch'] + 1\n",
        "\n",
        "    #(5) Create new feature IsAlone from FamilySize\n",
        "    data['IsAlone'] = 0\n",
        "    data.loc[data['Family_Size'] == 1, 'IsAlone'] = 1\n",
        "\n",
        "    #(6)Fare Bins pushed into 4 quantiles\n",
        "    ''' CategoricalFare  Survived\n",
        "    0       [0, 7.91]  0.197309\n",
        "    1  (7.91, 14.454]  0.303571\n",
        "    2    (14.454, 31]  0.454955\n",
        "    3   (31, 512.329]  0.581081\n",
        "    '''\n",
        "    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n",
        "    data.loc[ data['Fare'] > 31, 'Fare']  = 3\n",
        "    data['Fare'] = data['Fare'].astype(int)\n",
        "\n",
        "     #(7) Create a new feature Title, containing the titles of passenger names. Replace rare titles with \"rare\"\n",
        "    #replace and fix miss spellings\n",
        "    #map str to intergrers and fill none with 0\n",
        "    '''\n",
        "    Capt           0     1\n",
        "    Col            0     2\n",
        "    Countess       1     0\n",
        "    Don            0     1\n",
        "    Dr             1     6\n",
        "    Jonkheer       0     1\n",
        "    Lady           1     0\n",
        "    Major          0     2\n",
        "    Master         0    40\n",
        "    Miss         182     0\n",
        "    Mlle           2     0\n",
        "    Mme            1     0\n",
        "    Mr             0   517\n",
        "    Mrs          125     0\n",
        "    Ms             1     0\n",
        "    Rev            0     6\n",
        "    Sir            0     1\n",
        "    '''\n",
        "    data['Title'] = data['Name'].apply(get_title)\n",
        "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
        "    data['Title'] = data['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})\n",
        "    data['Title'] = data['Title'].fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "    #(8)drop all cases without age`\n",
        "    data = data.dropna(subset=['Age'])\n",
        "\n",
        "    #drop non usable variables\n",
        "    data = data.drop('Ticket', axis=1)\n",
        "    data = data.drop('Cabin', axis=1)\n",
        "    data = data.drop('Name', axis=1)\n",
        "    data = data.drop('PassengerId', axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    #(9)drop any rows with missing data\n",
        "    data = data.dropna()\n",
        "\n",
        "    print(data.info())\n",
        "\n",
        "\n",
        "    return(data)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:05.965905Z",
          "iopub.execute_input": "2023-12-13T17:42:05.966712Z",
          "iopub.status.idle": "2023-12-13T17:42:05.979021Z",
          "shell.execute_reply.started": "2023-12-13T17:42:05.966668Z",
          "shell.execute_reply": "2023-12-13T17:42:05.978136Z"
        },
        "trusted": true,
        "id": "JJIxWD3gXIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing_test(test_path):\n",
        "\n",
        "    data=pd.read_csv(test_path)\n",
        "\n",
        "    #(1)convert Sex to numeric\n",
        "    data['Sex'] = data['Sex'].map({'male': 1, 'female': 0})\n",
        "\n",
        "    #(2)set embarked to S if not stated\n",
        "    data['Embarked'] = data['Embarked'].fillna('S')\n",
        "    data['Embarked'] = data['Embarked'].map({'Q': 2, 'S': 1, 'C': 0})\n",
        "\n",
        "    #(3)feature engineering: add feature that tells whether a passenger had a cabin on the Titanic\n",
        "    #use this since basin numbers are not usable\n",
        "    data['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "\n",
        "    # (4)Create new feature FamilySize as a combination of SibSp and Parch\n",
        "    data['Family_Size'] = data['SibSp'] + data['Parch'] + 1\n",
        "\n",
        "    #(5) Create new feature IsAlone from FamilySize\n",
        "    data['IsAlone'] = 0\n",
        "    data.loc[data['Family_Size'] == 1, 'IsAlone'] = 1\n",
        "\n",
        "    #(6)Fare Bins pushed into 4 quantiles\n",
        "    ''' CategoricalFare  Survived\n",
        "    0       [0, 7.91]  0.197309\n",
        "    1  (7.91, 14.454]  0.303571\n",
        "    2    (14.454, 31]  0.454955\n",
        "    3   (31, 512.329]  0.581081\n",
        "    '''\n",
        "    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n",
        "    data.loc[ data['Fare'] > 31, 'Fare']  = 3\n",
        "    #drop all cases without fare`\n",
        "    data = data.dropna(subset=['Fare'])\n",
        "    data['Fare'] = data['Fare'].astype(int)\n",
        "\n",
        "    # (7)Create a new feature Title, containing the titles of passenger names. Replace rare titles with \"rare\"\n",
        "    #replace and fix miss spellings\n",
        "    #map str to intergrers and fill none with 0\n",
        "    '''\n",
        "    Capt           0     1\n",
        "    Col            0     2\n",
        "    Countess       1     0\n",
        "    Don            0     1\n",
        "    Dr             1     6\n",
        "    Jonkheer       0     1\n",
        "    Lady           1     0\n",
        "    Major          0     2\n",
        "    Master         0    40\n",
        "    Miss         182     0\n",
        "    Mlle           2     0\n",
        "    Mme            1     0\n",
        "    Mr             0   517\n",
        "    Mrs          125     0\n",
        "    Ms             1     0\n",
        "    Rev            0     6\n",
        "    Sir            0     1\n",
        "    '''\n",
        "    data['Title'] = data['Name'].apply(get_title)\n",
        "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
        "    data['Title'] = data['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})\n",
        "    data['Title'] = data['Title'].fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "    #(8)drop all cases without age`\n",
        "    data = data.dropna(subset=['Age'])\n",
        "    #drop non usable variables\n",
        "    data = data.drop('Ticket', axis=1)\n",
        "    data = data.drop('Cabin', axis=1)\n",
        "    data = data.drop('Name', axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    #(10)drop any rows with missing data\n",
        "    data = data.dropna()\n",
        "\n",
        "    # (11) Add empty column for 'Predicted Survived'\n",
        "\n",
        "    data['Survived']=pd.Series(dtype='float64')\n",
        "\n",
        "    return(data)\n",
        "    #return(test_data, X_test, Y_test)\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:06.419233Z",
          "iopub.execute_input": "2023-12-13T17:42:06.419599Z",
          "iopub.status.idle": "2023-12-13T17:42:06.436816Z",
          "shell.execute_reply.started": "2023-12-13T17:42:06.419553Z",
          "shell.execute_reply": "2023-12-13T17:42:06.435792Z"
        },
        "trusted": true,
        "id": "K0XHT3-QXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=data_preprocessing_train(train_path)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:06.882Z",
          "iopub.execute_input": "2023-12-13T17:42:06.88235Z",
          "iopub.status.idle": "2023-12-13T17:42:06.918978Z",
          "shell.execute_reply.started": "2023-12-13T17:42:06.882324Z",
          "shell.execute_reply": "2023-12-13T17:42:06.91812Z"
        },
        "trusted": true,
        "id": "FBshnsxhXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_columns=[ 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Has_Cabin',\n",
        "       'IsAlone', 'Title']\n",
        "response_column=['Survived']\n",
        "\n",
        "X=train_data[predictor_columns]\n",
        "Y=train_data[response_column]\n",
        "\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:07.389722Z",
          "iopub.execute_input": "2023-12-13T17:42:07.39008Z",
          "iopub.status.idle": "2023-12-13T17:42:07.399347Z",
          "shell.execute_reply.started": "2023-12-13T17:42:07.390048Z",
          "shell.execute_reply": "2023-12-13T17:42:07.398217Z"
        },
        "trusted": true,
        "id": "QoRQUwXZXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Correlation:\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "traindata=train_data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Has_Cabin',\n",
        "       'IsAlone', 'Title','Survived']]\n",
        "\n",
        "# Calculate the covariance + Correlation matrix:\n",
        "cov_matrix = np.cov(traindata, rowvar=False)\n",
        "correlation_matrix = traindata.corr()\n",
        "\n",
        "# Create a heatmap of the covariance matrix\n",
        "plt.figure(figsize=(10, 6))\n",
        "#sns.heatmap(cov_matrix, annot=True, fmt=\"0.2f\",cmap='coolwarm', linewidths=0.5)\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "\n",
        "# Set the title\n",
        "plt.title('Correlation Matrix Heatmap',fontsize= 14)\n",
        "\n",
        "# Customize tick labels\n",
        "plt.xticks(np.arange(len(traindata.columns)), traindata.columns, rotation=45,fontsize=8)\n",
        "plt.yticks(np.arange(len(traindata.columns)), traindata.columns, rotation=0,fontsize=8)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:07.837135Z",
          "iopub.execute_input": "2023-12-13T17:42:07.837479Z",
          "iopub.status.idle": "2023-12-13T17:42:08.577002Z",
          "shell.execute_reply.started": "2023-12-13T17:42:07.837453Z",
          "shell.execute_reply": "2023-12-13T17:42:08.576297Z"
        },
        "trusted": true,
        "id": "Dw8ePnSzXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models to compare:\n",
        "*****************************************************"
      ],
      "metadata": {
        "id": "6Sos_TAqXIqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_selection import RFECV\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:08.753374Z",
          "iopub.execute_input": "2023-12-13T17:42:08.754014Z",
          "iopub.status.idle": "2023-12-13T17:42:08.759486Z",
          "shell.execute_reply.started": "2023-12-13T17:42:08.753984Z",
          "shell.execute_reply": "2023-12-13T17:42:08.758321Z"
        },
        "trusted": true,
        "id": "jdo-OAiGXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression without feature selection\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "logreg_model = LogisticRegression()\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "classification_rep = classification_report(y_val, y_pred)\n",
        "mse_logit=mean_squared_error(y_val,y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for logistic classifier {mse_logit:0.3f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:09.319154Z",
          "iopub.execute_input": "2023-12-13T17:42:09.319488Z",
          "iopub.status.idle": "2023-12-13T17:42:09.369708Z",
          "shell.execute_reply.started": "2023-12-13T17:42:09.319463Z",
          "shell.execute_reply": "2023-12-13T17:42:09.368542Z"
        },
        "trusted": true,
        "id": "hIjC1g51XIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Logistic regression with feature selection\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Create the Logistic Regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "\n",
        "# Create the RFECV model with cross-validation\n",
        "rfecv = RFECV(estimator=logreg_model, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
        "\n",
        "\n",
        "# Fit the RFECV model to the training data\n",
        "rfecv.fit(X_train, Y_train)\n",
        "\n",
        "# Get the optimal number of features\n",
        "optimal_num_features = rfecv.n_features_\n",
        "\n",
        "# Print the selected features\n",
        "selected_features = pd.DataFrame({'Feature': X.columns, 'Selected': rfecv.support_, 'Ranking': rfecv.ranking_})\n",
        "print(f\"Selected Features:\")\n",
        "print(selected_features)\n",
        "\n",
        "\n",
        "# Transform the training and testing sets to keep only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_val_selected = rfecv.transform(X_val)\n",
        "\n",
        "# Train the XGBoost model on the selected features\n",
        "logreg_model.fit(X_train_selected, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_val_selected)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(Y_val, y_pred)\n",
        "classification_rep = classification_report(Y_val, y_pred)\n",
        "mse_logreg=mean_squared_error(Y_val,y_pred)\n",
        "\n",
        "print(\"Optimal Number of Features:\", optimal_num_features)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for LogREg Classifier = {mse_logreg:0.3f}\")\n",
        "\n",
        "\n",
        "log_reg_selected_feature=selected_features.loc[selected_features['Ranking']==1,'Feature']\n",
        "log_reg_selected_feature"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:09.866284Z",
          "iopub.execute_input": "2023-12-13T17:42:09.86664Z",
          "iopub.status.idle": "2023-12-13T17:42:10.197166Z",
          "shell.execute_reply.started": "2023-12-13T17:42:09.866613Z",
          "shell.execute_reply": "2023-12-13T17:42:10.196285Z"
        },
        "trusted": true,
        "id": "1DPFtbwLXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: XGBOOST with feature elimination:\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Create the Logistic Regression model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "\n",
        "# Create the RFECV model with cross-validation\n",
        "rfecv = RFECV(estimator=xgb_model, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
        "\n",
        "\n",
        "# Fit the RFECV model to the training data\n",
        "rfecv.fit(X_train, Y_train)\n",
        "\n",
        "# Get the optimal number of features\n",
        "optimal_num_features = rfecv.n_features_\n",
        "\n",
        "# Print the selected features\n",
        "selected_features = pd.DataFrame({'Feature': X.columns, 'Selected': rfecv.support_, 'Ranking': rfecv.ranking_})\n",
        "print(f\"Selected Features:\")\n",
        "print(selected_features)\n",
        "\n",
        "\n",
        "# Transform the training and testing sets to keep only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_val_selected = rfecv.transform(X_val)\n",
        "\n",
        "# Train the XGBoost model on the selected features\n",
        "xgb_model.fit(X_train_selected, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_model.predict(X_val_selected)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(Y_val, y_pred)\n",
        "classification_rep = classification_report(Y_val, y_pred)\n",
        "mse_xgb=mean_squared_error(Y_val,y_pred)\n",
        "\n",
        "print(\"Optimal Number of Features:\", optimal_num_features)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for XGB Classifier = {mse_xgb:0.3f}\")\n",
        "\n",
        "xgb_selected_feature=selected_features.loc[selected_features['Ranking']==1,'Feature']\n",
        "print(pd.DataFrame({'Selected Feature': xgb_selected_feature,'Importance':xgb_model.feature_importances_}))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:10.310227Z",
          "iopub.execute_input": "2023-12-13T17:42:10.311121Z",
          "iopub.status.idle": "2023-12-13T17:42:12.245871Z",
          "shell.execute_reply.started": "2023-12-13T17:42:10.311049Z",
          "shell.execute_reply": "2023-12-13T17:42:12.244859Z"
        },
        "trusted": true,
        "id": "yTr1nkeXXIqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3: Random Forrest with feature elimination:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Create the Logistic Regression model\n",
        "rfc_model = RandomForestClassifier()\n",
        "\n",
        "\n",
        "# Create the RFECV model with cross-validation\n",
        "rfecv = RFECV(estimator=rfc_model, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
        "\n",
        "\n",
        "# Fit the RFECV model to the training data\n",
        "rfecv.fit(X_train, Y_train)\n",
        "\n",
        "# Get the optimal number of features\n",
        "optimal_num_features = rfecv.n_features_\n",
        "\n",
        "# Print the selected features\n",
        "selected_features = pd.DataFrame({'Feature': X.columns, 'Selected': rfecv.support_, 'Ranking': rfecv.ranking_})\n",
        "print(f\"Selected Features:\")\n",
        "print(selected_features)\n",
        "\n",
        "\n",
        "# Transform the training and testing sets to keep only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_val_selected = rfecv.transform(X_val)\n",
        "\n",
        "# Train the XGBoost model on the selected features\n",
        "rfc_model.fit(X_train_selected, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rfc_model.predict(X_val_selected)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(Y_val, y_pred)\n",
        "classification_rep = classification_report(Y_val, y_pred)\n",
        "mse_rfc=mean_squared_error(Y_val,y_pred)\n",
        "\n",
        "print(\"Optimal Number of Features:\", optimal_num_features)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for RandomForrest Classifier = {mse_rfc:0.3f}\")\n",
        "\n",
        "rfe_selected_feature=selected_features.loc[selected_features['Ranking']==1,'Feature']\n",
        "#print(rfe_selected_feature)\n",
        "\n",
        "print(pd.DataFrame({'Selected Feature': rfe_selected_feature,'Importance':rfc_model.feature_importances_}))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:12.248219Z",
          "iopub.execute_input": "2023-12-13T17:42:12.248867Z",
          "iopub.status.idle": "2023-12-13T17:42:19.336739Z",
          "shell.execute_reply.started": "2023-12-13T17:42:12.248801Z",
          "shell.execute_reply": "2023-12-13T17:42:19.335498Z"
        },
        "trusted": true,
        "id": "53rrlWMsXIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper parameter Tuning:\n",
        "*****************************************"
      ],
      "metadata": {
        "id": "XTNL8PYWXIqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Logistic Regression\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "X_selected= train_data[log_reg_selected_feature]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Logistic Regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'max_iter': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(estimator=logreg_model, param_grid=param_grid, cv=StratifiedKFold(5), scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Logistic Regression model with the best hyperparameters\n",
        "best_logreg_model = LogisticRegression(**best_params)\n",
        "best_logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_logreg_model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "classification_rep = classification_report(y_val, y_pred)\n",
        "mse_logreg=mean_squared_error(y_val,y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for best logreg Classifier={mse_logreg:0.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:19.338292Z",
          "iopub.execute_input": "2023-12-13T17:42:19.338921Z",
          "iopub.status.idle": "2023-12-13T17:42:38.575423Z",
          "shell.execute_reply.started": "2023-12-13T17:42:19.33889Z",
          "shell.execute_reply": "2023-12-13T17:42:38.574419Z"
        },
        "trusted": true,
        "id": "Kj16x_0dXIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Random Forrest Classifier:\n",
        "\n",
        "X_selected= train_data[rfe_selected_feature]\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Random Forest Classifier model\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=StratifiedKFold(5), scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Random Forest model with the best hyperparameters on the selected features\n",
        "best_rf_model = RandomForestClassifier(**best_params)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_rf_model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "classification_rep = classification_report(y_val, y_pred)\n",
        "mse_rf=mean_squared_error(y_val,y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for best RF model={mse_rf:0.3f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:42:38.577429Z",
          "iopub.execute_input": "2023-12-13T17:42:38.577757Z",
          "iopub.status.idle": "2023-12-13T17:43:48.097479Z",
          "shell.execute_reply.started": "2023-12-13T17:42:38.57773Z",
          "shell.execute_reply": "2023-12-13T17:43:48.096128Z"
        },
        "trusted": true,
        "id": "Vctx8kl7XIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model XGB Classifier:\n",
        "\n",
        "X_selected= train_data[xgb_selected_feature]\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Define a parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=StratifiedKFold(5), scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Random Forest model with the best hyperparameters on the selected features\n",
        "best_xgb_model = XGBClassifier(**best_params)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_xgb_model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "classification_rep = classification_report(y_val, y_pred)\n",
        "mse_xgb=mean_squared_error(y_val,y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for best XGB model={mse_xgb:0.3f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:43:48.098756Z",
          "iopub.execute_input": "2023-12-13T17:43:48.099048Z",
          "iopub.status.idle": "2023-12-13T17:44:48.019464Z",
          "shell.execute_reply.started": "2023-12-13T17:43:48.099007Z",
          "shell.execute_reply": "2023-12-13T17:44:48.018096Z"
        },
        "trusted": true,
        "id": "_9TgZoYqXIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the Model on the test Set:\n",
        "*****************************************************************"
      ],
      "metadata": {
        "id": "bgxgGRk-XIqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=data_preprocessing_test(test_path)\n",
        "test_data.shape\n",
        "test_data.columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.020695Z",
          "iopub.execute_input": "2023-12-13T17:44:48.020954Z",
          "iopub.status.idle": "2023-12-13T17:44:48.05499Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.020932Z",
          "shell.execute_reply": "2023-12-13T17:44:48.05387Z"
        },
        "trusted": true,
        "id": "YYXcOLo1XIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1)Fitting XGBOOST:\n",
        "****************"
      ],
      "metadata": {
        "id": "kjZGKbabXIqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#prepare the test data predictors based on the features selected by the best chosen model\n",
        "X_test = test_data[ xgb_selected_feature]\n",
        "X_test.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.0563Z",
          "iopub.execute_input": "2023-12-13T17:44:48.056587Z",
          "iopub.status.idle": "2023-12-13T17:44:48.068471Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.056548Z",
          "shell.execute_reply": "2023-12-13T17:44:48.067608Z"
        },
        "trusted": true,
        "id": "caq78911XIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=best_xgb_model.predict(X_test)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.06949Z",
          "iopub.execute_input": "2023-12-13T17:44:48.06977Z",
          "iopub.status.idle": "2023-12-13T17:44:48.083708Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.069747Z",
          "shell.execute_reply": "2023-12-13T17:44:48.082937Z"
        },
        "trusted": true,
        "id": "M4TYKLR8XIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prep the result table with passenger Id and Survival:\n",
        "\n",
        "test_data['Survived']=Y_test\n",
        "result_table=test_data[['PassengerId','Survived']]\n",
        "result_table"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.084604Z",
          "iopub.execute_input": "2023-12-13T17:44:48.084875Z",
          "iopub.status.idle": "2023-12-13T17:44:48.100677Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.084851Z",
          "shell.execute_reply": "2023-12-13T17:44:48.099554Z"
        },
        "trusted": true,
        "id": "zImtTZl7XIqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Count the occurrences of each category\n",
        "category_counts = result_table['Survived'].value_counts()\n",
        "\n",
        "\n",
        "ax=category_counts.plot(kind='barh', color='skyblue')\n",
        "\n",
        "# Change category names on the x-axis\n",
        "category_names = ['Not Survived', 'survived']\n",
        "ax.set_yticklabels(category_names, rotation=0)\n",
        "\n",
        "# Annotate each bar with its height\n",
        "#for p in ax.patches:\n",
        "    #ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                #ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "\n",
        "# Annotate each bar with its width\n",
        "for p in ax.patches:\n",
        "    ax.annotate(str(p.get_width()), (p.get_width(), p.get_y() + p.get_height() / 2.),\n",
        "                ha='center', va='center', xytext=(10, 0), textcoords='offset points')\n",
        "\n",
        "\n",
        "# Add labels and title\n",
        "plt.ylabel('Survived')\n",
        "plt.xlabel('Count')\n",
        "plt.title('Bar Plot of Survived Counts: XGBOOST Model')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.104568Z",
          "iopub.execute_input": "2023-12-13T17:44:48.104955Z",
          "iopub.status.idle": "2023-12-13T17:44:48.367913Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.104922Z",
          "shell.execute_reply": "2023-12-13T17:44:48.366758Z"
        },
        "trusted": true,
        "id": "pGR1MH_kXIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Fitting Random Forrest Classifier model:\n",
        "*********************************************************************"
      ],
      "metadata": {
        "id": "yF3uJ3eRXIqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the test data predictors based on the features selected by the best chosen model\n",
        "X_test = test_data[ rfe_selected_feature]\n",
        "X_test.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.369282Z",
          "iopub.execute_input": "2023-12-13T17:44:48.369553Z",
          "iopub.status.idle": "2023-12-13T17:44:48.380233Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.369531Z",
          "shell.execute_reply": "2023-12-13T17:44:48.379063Z"
        },
        "trusted": true,
        "id": "EpY3n8R0XIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=best_rf_model.predict(X_test)\n",
        "\n",
        "# Prep the result table with passenger Id and Survival:\n",
        "\n",
        "test_data['Survived']=Y_test\n",
        "result_table=test_data[['PassengerId','Survived']]\n",
        "result_table"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.381945Z",
          "iopub.execute_input": "2023-12-13T17:44:48.382295Z",
          "iopub.status.idle": "2023-12-13T17:44:48.405784Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.382272Z",
          "shell.execute_reply": "2023-12-13T17:44:48.404918Z"
        },
        "trusted": true,
        "id": "JkKLHbCVXIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Count the occurrences of each category\n",
        "category_counts = result_table['Survived'].value_counts()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "ax=category_counts.plot(kind='barh', color='skyblue')\n",
        "\n",
        "# Change category names on the x-axis\n",
        "category_names = ['Not Survived', 'survived']\n",
        "ax.set_yticklabels(category_names, rotation=0)\n",
        "\n",
        "# Annotate each bar with its height\n",
        "#for p in ax.patches:\n",
        "    #ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                #ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "\n",
        "# Annotate each bar with its width\n",
        "for p in ax.patches:\n",
        "    ax.annotate(str(p.get_width()), (p.get_width(), p.get_y() + p.get_height() / 2.),\n",
        "                ha='center', va='center', xytext=(10, 0), textcoords='offset points')\n",
        "\n",
        "\n",
        "# Add labels and title\n",
        "plt.ylabel('Survived')\n",
        "plt.xlabel('Count')\n",
        "plt.title('Bar Plot of Survived Counts: Random Forrest Classifier Model')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.407308Z",
          "iopub.execute_input": "2023-12-13T17:44:48.407561Z",
          "iopub.status.idle": "2023-12-13T17:44:48.646311Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.407538Z",
          "shell.execute_reply": "2023-12-13T17:44:48.645433Z"
        },
        "trusted": true,
        "id": "6FzlqjIGXIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section deals with the case if we have considered the whole train dataset, not divided into validation and training subsets.\n",
        "******************************************************************************"
      ],
      "metadata": {
        "id": "tvJ9fZ68XIqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forrest Model:\n",
        "X_rf=train_data[rfe_selected_feature]\n",
        "\n",
        "best_rf_model.fit(X_rf,Y)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_rf_model.predict(X_rf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y, y_pred)\n",
        "conf_matrix = confusion_matrix(Y, y_pred)\n",
        "classification_rep = classification_report(Y, y_pred)\n",
        "mse_xgb=mean_squared_error(Y,y_pred)\n",
        "\n",
        "print('Best RF Model:\\n', best_rf_model)\n",
        "#print(\"Best Hyperparameters:\\n\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for best RF model={mse_xgb:0.3f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.647555Z",
          "iopub.execute_input": "2023-12-13T17:44:48.647848Z",
          "iopub.status.idle": "2023-12-13T17:44:48.837638Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.647825Z",
          "shell.execute_reply": "2023-12-13T17:44:48.836659Z"
        },
        "trusted": true,
        "id": "pUn-A2T6XIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB Model\n",
        "X_xgb=train_data[xgb_selected_feature]\n",
        "\n",
        "best_xgb_model.fit(X_xgb,Y)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_xgb_model.predict(X_xgb)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y, y_pred)\n",
        "conf_matrix = confusion_matrix(Y, y_pred)\n",
        "classification_rep = classification_report(Y, y_pred)\n",
        "mse_xgb=mean_squared_error(Y,y_pred)\n",
        "\n",
        "print('Best XGB Model:', best_xgb_model)\n",
        "#print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(f\"MSE for best XGB model={mse_xgb:0.3f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-13T17:44:48.838447Z",
          "iopub.execute_input": "2023-12-13T17:44:48.838754Z",
          "iopub.status.idle": "2023-12-13T17:44:48.901066Z",
          "shell.execute_reply.started": "2023-12-13T17:44:48.838728Z",
          "shell.execute_reply": "2023-12-13T17:44:48.899724Z"
        },
        "trusted": true,
        "id": "ntsaX3ItXIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdBnDtklXIqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}